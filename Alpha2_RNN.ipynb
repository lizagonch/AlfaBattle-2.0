{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alpha2_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "32cf2748d4e14643bb3dffdb95ef35ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5bd97f2950a5460baf87cbb06f145b6f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f83a4b3821b4f8996189df08c2d3154",
              "IPY_MODEL_6a24263462fd4887bc677d4efe16d683"
            ]
          }
        },
        "5bd97f2950a5460baf87cbb06f145b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f83a4b3821b4f8996189df08c2d3154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39b1f870e3164f75ae1ff979dfa07abc",
            "_dom_classes": [],
            "description": "Reading dataset with pandas: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f8ed92407c34ed99ed799effb03e071"
          }
        },
        "6a24263462fd4887bc677d4efe16d683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_723e621eded6462bb01fb8838977790d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:05&lt;00:00,  5.83s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c80d1a8026fb40b99d39fdbb55f3a3de"
          }
        },
        "39b1f870e3164f75ae1ff979dfa07abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f8ed92407c34ed99ed799effb03e071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "723e621eded6462bb01fb8838977790d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c80d1a8026fb40b99d39fdbb55f3a3de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60708ad396824f2bb04c451b84ba31ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7a3ceaeb2dd462791ad5e8245868ac6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d12fe2cc3b04ee6bb756e8edfd9fb8b",
              "IPY_MODEL_ce918bf2520d4593b905a99ee956a1c8"
            ]
          }
        },
        "e7a3ceaeb2dd462791ad5e8245868ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d12fe2cc3b04ee6bb756e8edfd9fb8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_18f9a51031314806b5817c08908f63a4",
            "_dom_classes": [],
            "description": "Reading dataset with pandas: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf0705461d5a4d249167435482a7cc29"
          }
        },
        "ce918bf2520d4593b905a99ee956a1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_43a43d6643eb4a15a038264397f5cbe9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:01&lt;00:00,  1.40s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e867848f6e9d42cc91ab410852ec53d2"
          }
        },
        "18f9a51031314806b5817c08908f63a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf0705461d5a4d249167435482a7cc29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43a43d6643eb4a15a038264397f5cbe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e867848f6e9d42cc91ab410852ec53d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1zJseJdTP0r"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import gc\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm\n",
        "# import seaborn as sns\n",
        "\n",
        "# pd.set_option('display.max_columns', None)\n",
        "\n",
        "# если у вас есть CUDA, то она понадобится там для экспериментов в catboost\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWF_MBCaTe04"
      },
      "source": [
        "###Reading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8fQCZ_kuwJp"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "import time\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el6DvQJuEehZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHJAwPwpu19v",
        "outputId": "b3c23471-2e07-4968-f6b1-2d1d37d7143d"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGSF-nNcu3Uc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "39562d98-cf52-4193-acb3-691946b01b6b"
      },
      "source": [
        "zip_file = '/content/drive/MyDrive/alfabattle2_test_transactions_contest.zip'\n",
        "\n",
        "z = zipfile.ZipFile(zip_file, 'r')\n",
        "z.extractall()\n",
        "\n",
        "print(os.listdir())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5a65b8a3640d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mzip_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/alfabattle2_test_transactions_contest.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/alfabattle2_test_transactions_contest.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RR4F3M_u8Af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "123df319-20b9-4050-d7c3-36b70b868cac"
      },
      "source": [
        "zip_file = '/content/drive/MyDrive/alfabattle2_train_transactions_contest.zip'\n",
        "\n",
        "z = zipfile.ZipFile(zip_file, 'r')\n",
        "z.extractall()\n",
        "\n",
        "print(os.listdir())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7e91d5b92d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mzip_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/alfabattle2_train_transactions_contest.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/alfabattle2_train_transactions_contest.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTcMu9dPu9M3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f7d88e-f00a-4acc-f272-e7e1f75d9bda"
      },
      "source": [
        "zip_file = '/content/drive/MyDrive/alfabattle2.zip'\n",
        "\n",
        "z = zipfile.ZipFile(zip_file, 'r')\n",
        "z.extractall()\n",
        "\n",
        "print(os.listdir())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'alfabattle2_alpha_sample.csv', 'alfabattle2_train_target.csv', '__MACOSX', 'train_transactions_contest', 'alfabattle2_test_target_contest.csv', 'test_transactions_contest', 'drive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY6q5n3jvCmx",
        "outputId": "bffd0bcf-76ec-4bdc-9517-c377f16b47d3"
      },
      "source": [
        "zip_file = '/content/drive/MyDrive/utils_data.zip'\n",
        "\n",
        "z = zipfile.ZipFile(zip_file, 'r')\n",
        "z.extractall()\n",
        "\n",
        "print(os.listdir())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'alfabattle2_alpha_sample.csv', 'alfabattle2_train_target.csv', 'utils.py', 'batch_train_1.csv', '__MACOSX', 'train_transactions_contest', 'alfabattle2_test_target_contest.csv', 'test_transactions_contest', 'drive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka3LuLV3yj1X"
      },
      "source": [
        "from utils import read_parquet_dataset_from_local"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pejXoQlcu-lI"
      },
      "source": [
        "TRAIN_TRANSACTIONS_PATH = '/content/train_transactions_contest'\n",
        "TEST_TRANSACTIONS_PATH = '/content/test_transactions_contest'\n",
        "\n",
        "TRAIN_TARGET_PATH = '/content/alfabattle2_train_target.csv'\n",
        "TEST_TARGET_PATH = '/content/alfabattle2_test_target_contest.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry-Wmf74gXxz"
      },
      "source": [
        "###Reading partitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQcNTFoRzIJ5"
      },
      "source": [
        "def data_processing(transaction_path, targets_path, is_Test, num_parts):\n",
        "  data = read_parquet_dataset_from_local(transaction_path, start_from=0, num_parts_to_read=num_parts)\n",
        "\n",
        "  memory_usage_of_frame = data.memory_usage(index=True).sum() / 10**9\n",
        "  expected_memory_usage = memory_usage_of_frame * 50\n",
        "  print(f'Партиция : {0}')\n",
        "  print(f'Объем памяти в  RAM одной партиции данных с транзакциями: {round(memory_usage_of_frame, 3)} Gb')\n",
        "  print(f'Ожидаемый размер в RAM всего датасета: {round(expected_memory_usage, 3)} Gb')\n",
        "  \n",
        "  data.amnt.replace(0.0, np.nan, regex=False, inplace = True)\n",
        "  targets = pd.read_csv(targets_path)\n",
        "  if (is_Test):\n",
        "    data = data.merge(targets[['app_id', 'product']], on='app_id')\n",
        "  else:\n",
        "    data = data.merge(targets[['app_id', 'product', 'flag']], on=['app_id'])\n",
        "  \n",
        "  data[\"Is_end_of_week\"] = data['day_of_week'].isin([5,6,7])\n",
        "  data[\"Is_holidays\"] = data['weekofyear'].isin([1,2,9,10,18,19,51,52,53])\n",
        "\n",
        "  data['amnt'] = data['amnt'].fillna(data.groupby('app_id')['amnt'].transform('mean'))\n",
        "  return data, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "32cf2748d4e14643bb3dffdb95ef35ad",
            "5bd97f2950a5460baf87cbb06f145b6f",
            "3f83a4b3821b4f8996189df08c2d3154",
            "6a24263462fd4887bc677d4efe16d683",
            "39b1f870e3164f75ae1ff979dfa07abc",
            "5f8ed92407c34ed99ed799effb03e071",
            "723e621eded6462bb01fb8838977790d",
            "c80d1a8026fb40b99d39fdbb55f3a3de"
          ]
        },
        "id": "QMuxp4VO2Xkn",
        "outputId": "a62dad2e-bf13-4cd6-c3df-ff06a7b8daf6"
      },
      "source": [
        "new_data, target_frame = data_processing(TRAIN_TRANSACTIONS_PATH, TRAIN_TARGET_PATH, False, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32cf2748d4e14643bb3dffdb95ef35ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Reading dataset with pandas', max=1.0, style=ProgressStyl…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Партиция : 0\n",
            "Объем памяти в  RAM одной партиции данных с транзакциями: 0.476 Gb\n",
            "Ожидаемый размер в RAM всего датасета: 23.798 Gb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "60708ad396824f2bb04c451b84ba31ea",
            "e7a3ceaeb2dd462791ad5e8245868ac6",
            "9d12fe2cc3b04ee6bb756e8edfd9fb8b",
            "ce918bf2520d4593b905a99ee956a1c8",
            "18f9a51031314806b5817c08908f63a4",
            "cf0705461d5a4d249167435482a7cc29",
            "43a43d6643eb4a15a038264397f5cbe9",
            "e867848f6e9d42cc91ab410852ec53d2"
          ]
        },
        "id": "h-FVHe1E35s0",
        "outputId": "0e355606-18ef-46e3-8268-bff799b62166"
      },
      "source": [
        "merged_test_data, test_target = data_processing(TEST_TRANSACTIONS_PATH, TEST_TARGET_PATH, True, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60708ad396824f2bb04c451b84ba31ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Reading dataset with pandas', max=1.0, style=ProgressStyl…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Партиция : 0\n",
            "Объем памяти в  RAM одной партиции данных с транзакциями: 0.305 Gb\n",
            "Ожидаемый размер в RAM всего датасета: 15.236 Gb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "yO_2taf5Tc67",
        "outputId": "2e142de1-eda2-4e62-8253-0d00e65f54bf"
      },
      "source": [
        "new_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>amnt</th>\n",
              "      <th>currency</th>\n",
              "      <th>operation_kind</th>\n",
              "      <th>card_type</th>\n",
              "      <th>operation_type</th>\n",
              "      <th>operation_type_group</th>\n",
              "      <th>ecommerce_flag</th>\n",
              "      <th>payment_system</th>\n",
              "      <th>income_flag</th>\n",
              "      <th>mcc</th>\n",
              "      <th>country</th>\n",
              "      <th>city</th>\n",
              "      <th>mcc_category</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>hour</th>\n",
              "      <th>days_before</th>\n",
              "      <th>weekofyear</th>\n",
              "      <th>hour_diff</th>\n",
              "      <th>transaction_number</th>\n",
              "      <th>product</th>\n",
              "      <th>flag</th>\n",
              "      <th>Is_end_of_week</th>\n",
              "      <th>Is_holidays</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.465425</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>98</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>351</td>\n",
              "      <td>34</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.390965</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>98</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>351</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.521152</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>98</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>351</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.356078</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>348</td>\n",
              "      <td>34</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.390965</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>98</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>337</td>\n",
              "      <td>53</td>\n",
              "      <td>280</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408643</th>\n",
              "      <td>23646</td>\n",
              "      <td>0.390944</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>32</td>\n",
              "      <td>453</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408644</th>\n",
              "      <td>23646</td>\n",
              "      <td>0.428447</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>27</td>\n",
              "      <td>454</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408645</th>\n",
              "      <td>23646</td>\n",
              "      <td>0.371478</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>455</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408646</th>\n",
              "      <td>23646</td>\n",
              "      <td>0.348726</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>456</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5408647</th>\n",
              "      <td>23646</td>\n",
              "      <td>0.324316</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>457</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5408648 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         app_id      amnt  currency  ...  flag  Is_end_of_week  Is_holidays\n",
              "0             0  0.465425         1  ...     0           False        False\n",
              "1             0  0.390965         1  ...     0           False        False\n",
              "2             0  0.521152         1  ...     0           False        False\n",
              "3             0  0.356078         1  ...     0           False        False\n",
              "4             0  0.390965         1  ...     0           False         True\n",
              "...         ...       ...       ...  ...   ...             ...          ...\n",
              "5408643   23646  0.390944         1  ...     0            True        False\n",
              "5408644   23646  0.428447         1  ...     0            True        False\n",
              "5408645   23646  0.371478         1  ...     0            True        False\n",
              "5408646   23646  0.348726         1  ...     0            True        False\n",
              "5408647   23646  0.324316         1  ...     0            True        False\n",
              "\n",
              "[5408648 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "BRTO2ix2grNZ",
        "outputId": "7701fe57-3dee-4de5-9a4b-e0668ea3796f"
      },
      "source": [
        "target_frame"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>product</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963806</th>\n",
              "      <td>1003045</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963807</th>\n",
              "      <td>1003047</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963808</th>\n",
              "      <td>1003048</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963809</th>\n",
              "      <td>1003049</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963810</th>\n",
              "      <td>1003050</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>963811 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         app_id  product  flag\n",
              "0             0        3     0\n",
              "1             1        1     0\n",
              "2             2        1     0\n",
              "3             3        1     0\n",
              "4             4        1     0\n",
              "...         ...      ...   ...\n",
              "963806  1003045        1     0\n",
              "963807  1003047        0     0\n",
              "963808  1003048        1     0\n",
              "963809  1003049        0     0\n",
              "963810  1003050        1     0\n",
              "\n",
              "[963811 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z62uzTmmauFd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eoNhECva0ZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e176c30-7482-44c1-8ad4-7f74b6952264"
      },
      "source": [
        "train_data, val = train_test_split(target_frame, random_state=42, test_size=0.1)\n",
        "train_data.shape, val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((867429, 3), (96382, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb_wj5INgs51"
      },
      "source": [
        "train = new_data.loc[new_data['app_id'].isin(train_data.app_id.values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyFr-VOOg9vQ",
        "outputId": "8b45e8a3-f68c-4b1f-9ac7-db37374807dd"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4852424, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL1JBW40hADt"
      },
      "source": [
        "val_data = new_data.loc[new_data['app_id'].isin(val.app_id.values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "bKxUc2pChCv5",
        "outputId": "726fef6d-9929-4dab-e1c8-dcf4954dde08"
      },
      "source": [
        "train.groupby(\"app_id\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amnt</th>\n",
              "      <th>currency</th>\n",
              "      <th>operation_kind</th>\n",
              "      <th>card_type</th>\n",
              "      <th>operation_type</th>\n",
              "      <th>operation_type_group</th>\n",
              "      <th>ecommerce_flag</th>\n",
              "      <th>payment_system</th>\n",
              "      <th>income_flag</th>\n",
              "      <th>mcc</th>\n",
              "      <th>country</th>\n",
              "      <th>city</th>\n",
              "      <th>mcc_category</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>hour</th>\n",
              "      <th>days_before</th>\n",
              "      <th>weekofyear</th>\n",
              "      <th>hour_diff</th>\n",
              "      <th>transaction_number</th>\n",
              "      <th>product</th>\n",
              "      <th>flag</th>\n",
              "      <th>Is_end_of_week</th>\n",
              "      <th>Is_holidays</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23642</th>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23643</th>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23644</th>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "      <td>404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23645</th>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23646</th>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "      <td>457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20445 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        amnt  currency  operation_kind  ...  flag  Is_end_of_week  Is_holidays\n",
              "app_id                                  ...                                   \n",
              "0        181       181             181  ...   181             181          181\n",
              "1        356       356             356  ...   356             356          356\n",
              "2        229       229             229  ...   229             229          229\n",
              "3         67        67              67  ...    67              67           67\n",
              "4        117       117             117  ...   117             117          117\n",
              "...      ...       ...             ...  ...   ...             ...          ...\n",
              "23642    161       161             161  ...   161             161          161\n",
              "23643    199       199             199  ...   199             199          199\n",
              "23644    404       404             404  ...   404             404          404\n",
              "23645    197       197             197  ...   197             197          197\n",
              "23646    457       457             457  ...   457             457          457\n",
              "\n",
              "[20445 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5R9MD0XiVMx"
      },
      "source": [
        "###Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB2JyOKAwo6v"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWf72pOTyJN3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNIegXBcyKxz",
        "outputId": "259f92dd-6f01-4c23-ebdf-af4332871b88"
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU not available, CPU used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "Gu7UIsxRiYWN",
        "outputId": "d2c06765-8456-44d1-e072-296764a381a0"
      },
      "source": [
        "val_data.groupby(\"flag\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>amnt</th>\n",
              "      <th>currency</th>\n",
              "      <th>operation_kind</th>\n",
              "      <th>card_type</th>\n",
              "      <th>operation_type</th>\n",
              "      <th>operation_type_group</th>\n",
              "      <th>ecommerce_flag</th>\n",
              "      <th>payment_system</th>\n",
              "      <th>income_flag</th>\n",
              "      <th>mcc</th>\n",
              "      <th>country</th>\n",
              "      <th>city</th>\n",
              "      <th>mcc_category</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>hour</th>\n",
              "      <th>days_before</th>\n",
              "      <th>weekofyear</th>\n",
              "      <th>hour_diff</th>\n",
              "      <th>transaction_number</th>\n",
              "      <th>product</th>\n",
              "      <th>Is_end_of_week</th>\n",
              "      <th>Is_holidays</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>flag</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      app_id    amnt  currency  ...  product  Is_end_of_week  Is_holidays\n",
              "flag                            ...                                      \n",
              "0     545219  545219    545219  ...   545219          545219       545219\n",
              "1      11005   11005     11005  ...    11005           11005        11005\n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e4axQ_-cSAb"
      },
      "source": [
        "###Prepare the class for storing the information about the users' card spendings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNebkpenik-G"
      },
      "source": [
        "class TabularDataset(Dataset):\n",
        "  def __init__(self, data, cat_cols=None, cont_cols=None, output_col=None, is_Train = True):\n",
        "    \"\"\"\n",
        "    Characterizes a Dataset for PyTorch\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    data: pandas data frame\n",
        "      The data frame object for the input data. It must\n",
        "      contain all the continuous, categorical and the\n",
        "      output columns to be used.\n",
        "\n",
        "    cat_cols: List of strings\n",
        "      The names of the categorical columns in the data.\n",
        "      These columns will be passed through the embedding\n",
        "      layers in the model. These columns must be\n",
        "      label encoded beforehand. \n",
        "\n",
        "    output_col: string\n",
        "      The name of the output variable column in the data\n",
        "      provided.\n",
        "    \"\"\"\n",
        "    self.is_Train = is_Train\n",
        "    self.data = data.sort_values(['app_id', 'transaction_number'])\n",
        "\n",
        "    self.unique_ids = data.app_id.unique()\n",
        "\n",
        "    self.max_length = int(data[[\"app_id\", \"amnt\"]].groupby([\"app_id\"]).count().max().values[0])\n",
        "    self.max_id = int(data.iloc[data.shape[0]-1][\"app_id\"])\n",
        "\n",
        "    self.seq_counts = [x[0] for x in (data[[\"app_id\", \"amnt\"]].groupby([\"app_id\"]).count().values)]\n",
        "\n",
        "    self.n = self.unique_ids.size#self.max_id + 1#data.shape[0]\n",
        "\n",
        "    ## app_id of the dataframe\n",
        "    #self.ids = merged_data[\"app_id\"].astype(np.float32).values\n",
        "    self.ids = {}\n",
        "    k = 0\n",
        "    for d in data[\"app_id\"]:\n",
        "      if (d not in self.ids.keys()):\n",
        "        self.ids[d] = [k]\n",
        "      else:\n",
        "        self.ids[d].append(k)\n",
        "      k += 1\n",
        "\n",
        "    if output_col:\n",
        "      self.y = data[output_col].astype(np.float32).values.reshape(-1, 1)#int64\n",
        "    else:\n",
        "      self.y =  np.zeros((data.shape[0], 1))\n",
        "\n",
        "    self.cat_cols = cat_cols if cat_cols else []\n",
        "    self.cont_cols = cont_cols  if cont_cols else []\n",
        "    \n",
        "    #[col for col in data.columns\n",
        "    #                 if col not in self.cat_cols + [output_col]]\n",
        "\n",
        "    if self.cont_cols:\n",
        "      self.cont_X = data[self.cont_cols].astype(np.float32).values\n",
        "    else:\n",
        "      self.cont_X = np.zeros((self.n, 1))\n",
        "\n",
        "    if self.cat_cols:\n",
        "      self.cat_X = data[cat_cols].astype(np.int64).values\n",
        "    else:\n",
        "      self.cat_X =  np.zeros((self.n, 1))\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "    Denotes the total number of samples.\n",
        "    \"\"\"\n",
        "    return self.n\n",
        "\n",
        "  def __getitem__(self, id):\n",
        "    \"\"\"\n",
        "    Generates one sample of data.\n",
        "    idx is a number of app_id\n",
        "    \"\"\"\n",
        "    #print(self.unique_ids)\n",
        "    idx = self.unique_ids[id]\n",
        "    #print(self.unique_ids[id])\n",
        "    \n",
        "    #target = np.zeros(2, dtype=np.int64)#len(self.ids[idx])\n",
        "    target = np.zeros(len(self.ids[idx]), dtype=np.float32)#int64\n",
        "    out_cat = np.zeros((len(self.ids[idx]), len(self.cat_cols)), dtype=np.int64) # self.max_length # len(self.cat_cols + self.cont_cols)\n",
        "    out_cont = np.zeros((len(self.ids[idx]), len(self.cont_cols)), dtype=np.float32) # self.max_length\n",
        "    #print(out_cat.shape)\n",
        "    k = 0\n",
        "    for i in self.ids[idx]:\n",
        "      #print(self.ids[idx])\n",
        "      target[k] = self.y[i]\n",
        "      #print(self.cont_X[i])\n",
        "      out_cont[k] = self.cont_X[i]#, dtype=np.float32)\n",
        "      out_cat[k] = self.cat_X[i]\n",
        "      k += 1\n",
        "    #target[int(np.mean(self.y[i]))] = 1\n",
        "    tar = np.mean(target)\n",
        "      #out.append([self.y[i], self.cont_X[i], self.cat_X[i]])\n",
        "    if (self.is_Train):\n",
        "      return (tar, out_cat, out_cont, self.seq_counts[id])\n",
        "    else:\n",
        "      return (idx, out_cat, out_cont, self.seq_counts[id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeKg5EffinDK"
      },
      "source": [
        "cat_vars = ['currency', 'operation_kind', 'card_type',\n",
        "               'operation_type', 'operation_type_group', 'ecommerce_flag',\n",
        "               'payment_system', 'income_flag', 'mcc', 'country', 'city',\n",
        "               'mcc_category', 'day_of_week', 'hour','weekofyear', 'Is_end_of_week', 'Is_holidays', 'product']\n",
        "\n",
        "cont_vars = ['amnt', 'days_before', 'hour_diff']\n",
        "dep_var = 'flag'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj-76NdHkvh-"
      },
      "source": [
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icq8ZQVvkyyz"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class PadSequence:\n",
        "    def __call__(self, batch):\n",
        "\t\t  # Let's assume that each element in \"batch\" is a tuple (data, label).\n",
        "      # Sort the batch in the descending order\n",
        "      #print(batch)\n",
        "      sorted_batch = sorted(batch, key=lambda x: x[3], reverse=True)\n",
        "\t\t  # Get each sequence and pad it\n",
        "      \n",
        "      cat = [torch.LongTensor(x[1]) for x in sorted_batch]\n",
        "      #print(cat[2].shape)\n",
        "      cat_padded = torch.nn.utils.rnn.pad_sequence(cat, batch_first=True)\n",
        "      #print(cat_padded[2].shape)\n",
        "      cont = [torch.FloatTensor(preprocessing.StandardScaler().fit(x[2]).transform(x[2])) for x in sorted_batch]\n",
        "      cont_padded = torch.nn.utils.rnn.pad_sequence(cont, batch_first=True)\n",
        "\t\t  # Also need to store the length of each sequence\n",
        "\t\t  # This is later needed in order to unpad the sequences\n",
        "      lengths = torch.LongTensor([x[3] for x in sorted_batch])\n",
        "      # Don't forget to grab the labels of the *sorted* batch\n",
        "      labels = torch.FloatTensor([x[0] for x in sorted_batch])\n",
        "      return labels, cat_padded, cont_padded, lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh4fQDL_k07k"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoders = {}\n",
        "for cat_col in cat_vars:\n",
        "  label_encoders[cat_col] = LabelEncoder()\n",
        "  #train[cat_col] = label_encoders[cat_col].fit_transform(train[cat_col])\n",
        "  #val_data[cat_col] = label_encoders[cat_col].fit_transform(val_data[cat_col])\n",
        "  merged_test_data[cat_col] = label_encoders[cat_col].fit_transform(merged_test_data[cat_col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anJDwpUvk5ew"
      },
      "source": [
        "dataset = TabularDataset(data=train, cat_cols=cat_vars, cont_cols = cont_vars, output_col=dep_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ33-K-ym057"
      },
      "source": [
        "dataset_val = TabularDataset(data=val_data, cat_cols=cat_vars, cont_cols = cont_vars, output_col=dep_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlwNnOZJTpr-"
      },
      "source": [
        "dataset_test = TabularDataset(data=merged_test_data, cat_cols=cat_vars, cont_cols = cont_vars, is_Train = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3T9oYWlW7zk",
        "outputId": "35aedb1a-eb51-4bde-a67a-bdac10d5ea05"
      },
      "source": [
        "len(dataset_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOprFo_OY2hK",
        "outputId": "41ebf7ec-e9b9-4653-e0d8-b62bb4ff40c5"
      },
      "source": [
        "dataset_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1063620, array([[0, 0, 4, ..., 0, 0, 0],\n",
              "        [0, 0, 4, ..., 0, 0, 0],\n",
              "        [0, 0, 4, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 4, ..., 1, 0, 0],\n",
              "        [0, 0, 4, ..., 1, 0, 0],\n",
              "        [0, 0, 4, ..., 0, 0, 0]]), array([[ 3.6768672e-01,  3.5900000e+02, -1.0000000e+00],\n",
              "        [ 4.0360665e-01,  3.5800000e+02,  1.9000000e+01],\n",
              "        [ 3.5666594e-01,  3.5800000e+02,  0.0000000e+00],\n",
              "        ...,\n",
              "        [ 4.0348879e-01,  5.0000000e+00,  4.0000000e+00],\n",
              "        [ 3.5578224e-01,  5.0000000e+00,  1.0000000e+00],\n",
              "        [ 5.3325504e-01,  1.0000000e+00,  8.9000000e+01]], dtype=float32), 673)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "b3RUp2nAUqsf",
        "outputId": "73beeb1d-e5f5-4a21-ce85-79f3fd96d7a5"
      },
      "source": [
        "merged_test_data.groupby(\"app_id\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amnt</th>\n",
              "      <th>currency</th>\n",
              "      <th>operation_kind</th>\n",
              "      <th>card_type</th>\n",
              "      <th>operation_type</th>\n",
              "      <th>operation_type_group</th>\n",
              "      <th>ecommerce_flag</th>\n",
              "      <th>payment_system</th>\n",
              "      <th>income_flag</th>\n",
              "      <th>mcc</th>\n",
              "      <th>country</th>\n",
              "      <th>city</th>\n",
              "      <th>mcc_category</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>hour</th>\n",
              "      <th>days_before</th>\n",
              "      <th>weekofyear</th>\n",
              "      <th>hour_diff</th>\n",
              "      <th>transaction_number</th>\n",
              "      <th>product</th>\n",
              "      <th>Is_end_of_week</th>\n",
              "      <th>Is_holidays</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1063620</th>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "      <td>673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063621</th>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063622</th>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "      <td>895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063623</th>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063624</th>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074458</th>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "      <td>290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074459</th>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074460</th>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "      <td>265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074461</th>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074462</th>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "      <td>592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10522 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         amnt  currency  operation_kind  ...  product  Is_end_of_week  Is_holidays\n",
              "app_id                                   ...                                      \n",
              "1063620   673       673             673  ...      673             673          673\n",
              "1063621   219       219             219  ...      219             219          219\n",
              "1063622   895       895             895  ...      895             895          895\n",
              "1063623   630       630             630  ...      630             630          630\n",
              "1063624   127       127             127  ...      127             127          127\n",
              "...       ...       ...             ...  ...      ...             ...          ...\n",
              "1074458   290       290             290  ...      290             290          290\n",
              "1074459    22        22              22  ...       22              22           22\n",
              "1074460   265       265             265  ...      265             265          265\n",
              "1074461   112       112             112  ...      112             112          112\n",
              "1074462   592       592             592  ...      592             592          592\n",
              "\n",
              "[10522 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTWdf7RUT0YK",
        "outputId": "bd63b2ea-2ca6-4c91-b36d-d394cf290612"
      },
      "source": [
        "dataset_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1063620, array([[0, 0, 4, ..., 0, 0, 0],\n",
              "        [0, 0, 4, ..., 0, 0, 0],\n",
              "        [0, 0, 4, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 4, ..., 1, 0, 0],\n",
              "        [0, 0, 4, ..., 1, 0, 0],\n",
              "        [0, 0, 4, ..., 0, 0, 0]]), array([[ 3.6768672e-01,  3.5900000e+02, -1.0000000e+00],\n",
              "        [ 4.0360665e-01,  3.5800000e+02,  1.9000000e+01],\n",
              "        [ 3.5666594e-01,  3.5800000e+02,  0.0000000e+00],\n",
              "        ...,\n",
              "        [ 4.0348879e-01,  5.0000000e+00,  4.0000000e+00],\n",
              "        [ 3.5578224e-01,  5.0000000e+00,  1.0000000e+00],\n",
              "        [ 5.3325504e-01,  1.0000000e+00,  8.9000000e+01]], dtype=float32), 673)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "g2TgVPy5m1WS",
        "outputId": "07230e6b-2cf4-40db-e0f0-51e82c387fb4"
      },
      "source": [
        "val_data.groupby(\"flag\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>amnt</th>\n",
              "      <th>currency</th>\n",
              "      <th>operation_kind</th>\n",
              "      <th>card_type</th>\n",
              "      <th>operation_type</th>\n",
              "      <th>operation_type_group</th>\n",
              "      <th>ecommerce_flag</th>\n",
              "      <th>payment_system</th>\n",
              "      <th>income_flag</th>\n",
              "      <th>mcc</th>\n",
              "      <th>country</th>\n",
              "      <th>city</th>\n",
              "      <th>mcc_category</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>hour</th>\n",
              "      <th>days_before</th>\n",
              "      <th>weekofyear</th>\n",
              "      <th>hour_diff</th>\n",
              "      <th>transaction_number</th>\n",
              "      <th>product</th>\n",
              "      <th>Is_end_of_week</th>\n",
              "      <th>Is_holidays</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>flag</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "      <td>545219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "      <td>11005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      app_id    amnt  currency  ...  product  Is_end_of_week  Is_holidays\n",
              "flag                            ...                                      \n",
              "0     545219  545219    545219  ...   545219          545219       545219\n",
              "1      11005   11005     11005  ...    11005           11005        11005\n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Rm1kNEm9kE"
      },
      "source": [
        "###Weighted Random Sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGU9I5eHSr_N"
      },
      "source": [
        "target_list = torch.tensor([i[0] for i in dataset], dtype = torch.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp-5dZf0Txi9",
        "outputId": "c5fac8e8-4076-419c-836c-7fe58cae5b2f"
      },
      "source": [
        "target_list.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20445])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce0fxJZtm4ux",
        "outputId": "1c07761e-a6c6-4188-cea2-1cadbac857e2"
      },
      "source": [
        "def get_class_distribution(dataset_obj):\n",
        "    count_dict = {0:0, 1:0}\n",
        "    \n",
        "    for element in dataset_obj:\n",
        "        #print(element[1])\n",
        "        count_dict[element[0]] += 1\n",
        "            \n",
        "    return count_dict\n",
        "print(\"Distribution of classes: \\n\", get_class_distribution(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution of classes: \n",
            " {0: 19860, 1: 585}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOoi5r_zodOO"
      },
      "source": [
        "class_count = [i for i in get_class_distribution(dataset).values()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAwPs9YBogkN",
        "outputId": "d111e6f8-342d-4f7d-f0d2-72bfb2ae3ee8"
      },
      "source": [
        "class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
        "class_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.0352e-05, 1.7094e-03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5zagaAFouEN",
        "outputId": "4efd7f41-832e-4e14-f234-ab5cd27cdc37"
      },
      "source": [
        "class_weights_all = class_weights[target_list]\n",
        "print(class_weights_all)\n",
        "print(len(class_weights_all))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.0352e-05, 5.0352e-05, 5.0352e-05,  ..., 5.0352e-05, 5.0352e-05,\n",
            "        5.0352e-05])\n",
            "20445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY8rg8aUfhZp"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WyF53UkFVY3"
      },
      "source": [
        "weighted_sampler = WeightedRandomSampler(\n",
        "    weights=class_weights_all,\n",
        "    num_samples=len(class_weights_all),\n",
        "    replacement=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBk73L-JEO7W"
      },
      "source": [
        "Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr3XXNHyEIrS"
      },
      "source": [
        "target_list_val = torch.tensor([i[0] for i in dataset_val], dtype = torch.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAwFsqQiO0_Z",
        "outputId": "e0ea4ccf-3a90-4011-a1b8-35bd9b9c9b08"
      },
      "source": [
        "target_list_val.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2298])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3GnIuikO0_f",
        "outputId": "2e3292d5-bedc-4aa4-f2ca-4bbed09b2019"
      },
      "source": [
        "print(\"Distribution of classes for validation: \\n\", get_class_distribution(dataset_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution of classes for validation: \n",
            " {0: 2238, 1: 60}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PmO9xzrER3R",
        "outputId": "a32256e2-012b-4265-c073-c4e90daaacde"
      },
      "source": [
        "class_count_val = [i for i in get_class_distribution(dataset_val).values()]\n",
        "class_count_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2238, 60]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ4ILM44EzwM",
        "outputId": "8f716598-2b4f-4b9b-ba94-76ad2e75615e"
      },
      "source": [
        "class_weights_val = 1./torch.tensor(class_count_val, dtype=torch.float)\n",
        "class_weights_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0004, 0.0167])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTb6F0h-E4ui",
        "outputId": "9a545e17-d0af-40c0-fae9-ddca53d7df36"
      },
      "source": [
        "class_weights_all_val = class_weights_val[target_list_val]\n",
        "print(class_weights_all_val)\n",
        "print(len(class_weights_all_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0004, 0.0004, 0.0004,  ..., 0.0004, 0.0004, 0.0004])\n",
            "2298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRKDmt9NFHU_",
        "outputId": "c327b27f-6fb2-4bac-ccee-7b2c5736009c"
      },
      "source": [
        "len(class_weights_all_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRK9nuDbFLsB"
      },
      "source": [
        "weighted_sampler_val = WeightedRandomSampler(\n",
        "    weights=class_weights_all_val,\n",
        "    num_samples=len(class_weights_all_val),\n",
        "    replacement=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b98vJZjwFcuA"
      },
      "source": [
        "###Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24otlauxFWS2"
      },
      "source": [
        "batchsize = 128\n",
        "dataloader = DataLoader(dataset=dataset, shuffle=False, batch_size=batchsize, sampler=weighted_sampler, collate_fn=PadSequence())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gnic_NhIByl"
      },
      "source": [
        "###Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3EhQZZlIAFF"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, emb_dims, no_of_cont, emb_dropout, lin_dropout, top_classifier_units, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Embedding layers\n",
        "        self.emb_layers = nn.ModuleList([nn.Embedding(x, y)\n",
        "                                     for x, y in emb_dims])\n",
        "\n",
        "        no_of_embs = sum([y for x, y in emb_dims])\n",
        "        self.no_of_embs = no_of_embs\n",
        "        self.no_of_cont = no_of_cont\n",
        "\n",
        "        # Batch Norm Layers\n",
        "        #self.first_bn_layer = nn.BatchNorm1d(3)#self.no_of_cont)\n",
        "        #self.bn_layers = nn.ModuleList([nn.BatchNorm1d(size)\n",
        "        #                            for size in lin_layer_sizes])\n",
        "        \n",
        "        # Dropout Layers\n",
        "        self.emb_dropout_layer = nn.Dropout(emb_dropout)\n",
        "        #self.droput_layers = nn.ModuleList([nn.Dropout(size)\n",
        "        #                          for size in lin_layer_dropouts])\n",
        "        \n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        #self.rnn = nn.RNN(self.no_of_embs + self.no_of_cont, hidden_dim, n_layers, batch_first=True)   \n",
        "        \n",
        "        self.lstm = nn.GRU(self.no_of_embs + self.no_of_cont, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=False,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        self.top_classifier = nn.Linear(hidden_dim, top_classifier_units)\n",
        "        self.intermediate_activation = nn.ReLU()\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(top_classifier_units, output_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(lin_dropout)\n",
        "\n",
        "        #activation function\n",
        "        self.act = nn.Sigmoid()\n",
        "        #self.act = nn.Softmax(dim = 1)#\n",
        "    \n",
        "    def forward(self, cont_data, cat_data, seq_lengths):\n",
        "\n",
        "##embedding layers\n",
        "        if self.no_of_embs != 0:\n",
        "          x = [emb_layer(cat_data[:,:,i])\n",
        "            for i,emb_layer in enumerate(self.emb_layers)]\n",
        "          #print(cont_data.shape)\n",
        "          #print(\"Shape \", len(x), x[1].shape)\n",
        "          x = torch.cat(x, 2)\n",
        "          x = self.emb_dropout_layer(x)\n",
        "\n",
        "        #print(cont_data.shape)\n",
        "        #if self.no_of_cont != 0:\n",
        "          #print(cont_data.shape)\n",
        "          #print(cont_data[:].shape)\n",
        "          #normalized_cont_data = self.first_bn_layer(cont_data[:])\n",
        "\n",
        "        normalized_cont_data = cont_data\n",
        "\n",
        "        if self.no_of_embs != 0:\n",
        "          x = torch.cat([x, normalized_cont_data], 2) \n",
        "        else:\n",
        "          x = normalized_cont_data\n",
        "        ## emb\n",
        "\n",
        "        #packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(x, seq_lengths.cpu(),batch_first=True, enforce_sorted=False)\n",
        "        #print(\"packed_emb\", packed_embedded)\n",
        "        #print(\"packed_emb\", packed_embedded.data[0].shape)\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        #print(\"Batch_size \", batch_size)\n",
        "\n",
        "        #Initializing hidden state for first input using method defined below\n",
        "        #hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        ###LSTM\n",
        "        #packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        _, hidden = self.lstm(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "        \n",
        "        #concat the final forward and backward hidden state\n",
        "        #hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        classification_hidden = self.top_classifier(self.dropout(hidden))\n",
        "        activation = self.intermediate_activation(classification_hidden)\n",
        "\n",
        "        dense_outputs=self.fc(activation)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.act(dense_outputs)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        #out, hidden = self.rnn(packed_embedded, hidden)\n",
        "\n",
        "        #row_indices = torch.arange(0, x.size(0)).long()\n",
        "        #col_indices = torch.LongTensor([355])\n",
        "        #if next(self.parameters()).is_cuda:\n",
        "        #    row_indices = row_indices.cuda()\n",
        "        #    col_indices = col_indices.cuda()\n",
        "\n",
        "        #if self.use_last:\n",
        "        #last_tensor=out[row_indices, col_indices, :]\n",
        "        #else:\n",
        "        #    # use mean\n",
        "        #    last_tensor = out[row_indices, :, :]\n",
        "        #    last_tensor = torch.mean(last_tensor, dim=1)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        #out = out.contiguous().view(-1, self.hidden_dim)\n",
        "        #print(\"RNN \", last_tensor)\n",
        "        #out = self.fc(out)\n",
        "        \n",
        "        return outputs\n",
        "    \n",
        "    #def init_hidden(self, batch_size):\n",
        "    #    # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "    #    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "    #     # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "    #    return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44R8MTQUFiA7",
        "outputId": "3821395d-6366-4d04-de0d-56ccecdb4edc"
      },
      "source": [
        "cat_dims = [int(new_data[col].nunique()) for col in cat_vars]\n",
        "print(cat_dims)\n",
        "\n",
        "emb_dims = [(x, min(50, (x + 1) // 2)) for x in cat_dims]\n",
        "emb_dims"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11, 7, 121, 20, 3, 3, 6, 3, 108, 24, 161, 28, 7, 24, 53, 2, 2, 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(11, 6),\n",
              " (7, 4),\n",
              " (121, 50),\n",
              " (20, 10),\n",
              " (3, 2),\n",
              " (3, 2),\n",
              " (6, 3),\n",
              " (3, 2),\n",
              " (108, 50),\n",
              " (24, 12),\n",
              " (161, 50),\n",
              " (28, 14),\n",
              " (7, 4),\n",
              " (24, 12),\n",
              " (53, 27),\n",
              " (2, 1),\n",
              " (2, 1),\n",
              " (4, 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szpPlPOacPAX"
      },
      "source": [
        "emb_dims = [(11, 6), \n",
        "            (7, 5),\n",
        "            (175, 29),\n",
        "            (22, 9),\n",
        "            (4, 3),\n",
        "            (3, 3),\n",
        "            (7, 5),\n",
        "            (3, 3),\n",
        "            (108, 22),\n",
        "            (24, 9),\n",
        "            (163, 28),\n",
        "            (28, 10),\n",
        "            (7, 5),\n",
        "            (24, 9),\n",
        "            (53, 15),\n",
        "            (2, 1),\n",
        "            (2, 1),\n",
        "            (4, 2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSRJLVbvIHvf"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Model(emb_dims, no_of_cont=3, emb_dropout=0.04, lin_dropout = 0.5, top_classifier_units = 32, output_size=1, hidden_dim=128, n_layers=1).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtvTe5gMIYZh",
        "outputId": "19c93b3b-dfe5-4b18-d2a9-7cb1e542f7bf"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (emb_layers): ModuleList(\n",
              "    (0): Embedding(11, 6)\n",
              "    (1): Embedding(7, 4)\n",
              "    (2): Embedding(121, 50)\n",
              "    (3): Embedding(20, 10)\n",
              "    (4): Embedding(3, 2)\n",
              "    (5): Embedding(3, 2)\n",
              "    (6): Embedding(6, 3)\n",
              "    (7): Embedding(3, 2)\n",
              "    (8): Embedding(108, 50)\n",
              "    (9): Embedding(24, 12)\n",
              "    (10): Embedding(161, 50)\n",
              "    (11): Embedding(28, 14)\n",
              "    (12): Embedding(7, 4)\n",
              "    (13): Embedding(24, 12)\n",
              "    (14): Embedding(53, 27)\n",
              "    (15): Embedding(2, 1)\n",
              "    (16): Embedding(2, 1)\n",
              "    (17): Embedding(4, 2)\n",
              "  )\n",
              "  (emb_dropout_layer): Dropout(p=0.04, inplace=False)\n",
              "  (lstm): GRU(255, 128, batch_first=True)\n",
              "  (top_classifier): Linear(in_features=128, out_features=32, bias=True)\n",
              "  (intermediate_activation): ReLU()\n",
              "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (act): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkZcLCe2Ib5j"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "#criterion = nn.BCELoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    #rounded_preds = torch.argmax(preds, dim = 1)\n",
        "    #print(rounded_preds)\n",
        "\n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "#push to cuda if available\n",
        "model = model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f604NvVwIfUg"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def roc_auc_score_s(preds, y) -> float:\n",
        "    \"\"\"\n",
        "    функция для оценки качества модели на отложенной выборке, возвращает roc-auc на валидационной\n",
        "    выборке\n",
        "    :param model: nn.Module модель\n",
        "    :param dataset_val: путь до директории с последовательностями\n",
        "    :param batch_size: размер батча\n",
        "    :param device: device, на который будут положены данные внутри батча\n",
        "    :return: val roc-auc score\n",
        "    \"\"\"\n",
        "    output = []\n",
        "    targets = []\n",
        "    #print(\"y \", y)\n",
        "    #print(\"pr \", preds)\n",
        "    targets.extend(y.detach().cpu().numpy().flatten())\n",
        "    #output = model(batch['transactions_features'], batch['product'])\n",
        "    output.extend(preds.detach().cpu().numpy().flatten())\n",
        "    #rounded_preds = torch.round(preds)\n",
        "    #print(output)\n",
        "\n",
        "    return roc_auc_score(targets, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G__h5668IpAP"
      },
      "source": [
        "def eval_model(model, dataset_val, weighted_sampler) -> float:\n",
        "    \"\"\"\n",
        "    функция для оценки качества модели на отложенной выборке, возвращает roc-auc на валидационной\n",
        "    выборке\n",
        "    :param model: nn.Module модель\n",
        "    :param dataset_val: путь до директории с последовательностями\n",
        "    :param batch_size: размер батча\n",
        "    :param device: device, на который будут положены данные внутри батча\n",
        "    :return: val roc-auc score\n",
        "    \"\"\"\n",
        "    preds = []\n",
        "    targets = []\n",
        "    batchsize = 64\n",
        "    val_dataloader = DataLoader(dataset=dataset_val, shuffle=False, batch_size=batchsize, sampler=weighted_sampler, collate_fn=PadSequence())\n",
        "    model.eval()\n",
        "    \n",
        "\n",
        "    for y, cat_x, cont_x, seq_length in val_dataloader:\n",
        "      cat_x = cat_x.to(device)\n",
        "      cont_x = cont_x.to(device)\n",
        "      y  = y.to(device)\n",
        "\n",
        "      preds = model(cont_x, cat_x, seq_length).squeeze()\n",
        "\n",
        "      acc = roc_auc_score_s(preds, y)\n",
        "\n",
        "    return acc.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwGCi8KCueOe"
      },
      "source": [
        "def inference(model, dataset_test, batch_size=32) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    функция, которая делает предикты на новых данных, возвращает pd.DataFrame из двух колонок:\n",
        "    (app_id, score)\n",
        "    :param model: nn.Module модель\n",
        "    :param dataset_test: путь до директории с последовательностями\n",
        "    :param batch_size: размер батча\n",
        "    :param device: device, на который будут положены данные внутри батча\n",
        "    :return: pd.DataFrame из двух колонок: (app_id, score)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    app_ids = []\n",
        "    test_dataloader = DataLoader(dataset=dataset_test, shuffle=False, batch_size=batch_size, collate_fn=PadSequence())\n",
        "\n",
        "    for app_id, cat_x, cont_x, seq_length in test_dataloader:\n",
        "        cat_x = cat_x.to(device)\n",
        "        cont_x = cont_x.to(device)\n",
        "        \n",
        "        app_ids.extend(app_id)\n",
        "        output =  model(cont_x, cat_x, seq_length).squeeze()\n",
        "        preds.extend(output.detach().cpu().numpy().flatten())\n",
        "        \n",
        "    return pd.DataFrame({\n",
        "        'app_id': app_ids,\n",
        "        'score': preds\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtrO48oMXoHk"
      },
      "source": [
        "test_dataloader = DataLoader(dataset=dataset_test, shuffle=False, batch_size=64, collate_fn=PadSequence())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpJcpbEoXyyA",
        "outputId": "6c5ad466-ebc3-4793-c2ec-7880cdd3347f"
      },
      "source": [
        "dat = next(iter(test_dataloader))\n",
        "  \n",
        "print(len(dat))\n",
        "print(dat[2][0])\n",
        "print(dat[2][0].mean(0))\n",
        "print(dat[2][0].var(0))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "tensor([[ 1.8033,  1.9097, -0.6562],\n",
            "        [ 1.7749,  1.9097, -0.5535],\n",
            "        [-0.9464,  1.8998,  0.2682],\n",
            "        ...,\n",
            "        [-3.7010, -1.6255, -0.5535],\n",
            "        [ 0.4854, -1.6255, -0.1427],\n",
            "        [ 0.2447, -1.6255, -0.5535]])\n",
            "tensor([ 9.6209e-09, -3.3673e-08, -6.3137e-09])\n",
            "tensor([1.0006, 1.0006, 1.0006])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN2HZBIE4tmw"
      },
      "source": [
        "def train_epoch(model, optimizer, dataset_train, weighted_sampler, batch_size=64, print_loss_every_n_batches=500):\n",
        "    \"\"\"\n",
        "    делает одну эпоху обучения модели, логирует\n",
        "    :param model: nn.Module модель\n",
        "    :param optimizer: nn.optim оптимизатор\n",
        "    :param dataset_train: путь до директории с последовательностями\n",
        "    :param batch_size: размерм батча\n",
        "    :param shuffle: флаг, если True, то перемешивает данные\n",
        "    :param print_loss_every_n_batches: число батчей после которых логируется лосс на этих батчах\n",
        "    :param device: device, на который будут положены данные внутри батча\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset_train, shuffle=False, batch_size=batch_size, sampler=weighted_sampler, collate_fn=PadSequence())\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    num_batches = 1\n",
        "    running_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for y, cat_x, cont_x, seq_length in dataloader:\n",
        "        cat_x = cat_x.to(device)\n",
        "        cont_x = cont_x.to(device)\n",
        "        y  = y.to(device)\n",
        "        seq_length = seq_length.to(device)\n",
        "\n",
        "        preds = model(cont_x, cat_x, seq_length).squeeze()\n",
        "\n",
        "        loss = criterion(preds, y)\n",
        "\n",
        "        acc = roc_auc_score_s(preds, y) \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        #print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()  \n",
        "        epoch_acc += acc.item()  \n",
        "\n",
        "        if num_batches % print_loss_every_n_batches == 0:\n",
        "            print(f'Training loss after {num_batches} batches: {running_loss / num_batches} roc-auc: {epoch_acc / num_batches}', end='\\r')\n",
        "        \n",
        "        num_batches += 1\n",
        "    \n",
        "    print(f'Training loss after epoch: {running_loss / num_batches}', end='\\r')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B87EXcEsC0Wq"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation metric doesn't improve after a given patience.\"\"\"\n",
        "\n",
        "    def __init__(self, patience=7, mode='min', verbose=False, delta=0, save_path='checkpoint.hdf5', metric_name=None, save_format='torch'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            mode (str): One of ['min', 'max'], whether to maximize or minimaze the metric.\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            save_path (str): Path to saved model\n",
        "        \"\"\"\n",
        "        if mode not in ['min', 'max']:\n",
        "            raise ValueError(f'Unrecognized mode: {mode}!')\n",
        "\n",
        "        self.patience = patience\n",
        "        self.mode = mode\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.best_prev_score = np.Inf if mode == 'min' else -np.Inf\n",
        "        self.delta = delta\n",
        "        self.save_path = save_path\n",
        "        self.metric_name = 'metric' if not metric_name else metric_name\n",
        "        if save_format not in ['torch', 'tf']:\n",
        "            raise ValueError('Expected to save in one of the following formats: [\"torch\", \"tf\"]')\n",
        "        self.save_format = save_format\n",
        "        \n",
        "    def __call__(self, metric_value, model):\n",
        "\n",
        "        score = -metric_value if self.mode == 'min' else metric_value\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(metric_value, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(\n",
        "                f'No imporvement in Validation {self.metric_name}. Current: {score:.6f}. Current best: {self.best_score:.6f}')\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(metric_value, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, metric_value, model):\n",
        "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
        "        if self.verbose:\n",
        "            print(\n",
        "                f'Validation {self.metric_name} improved ({self.best_prev_score:.6f} --> {metric_value:.6f}).  Saving model ...')\n",
        "        if self.save_format == 'tf':\n",
        "            model.save_weights(self.save_path)\n",
        "        else:\n",
        "            torch.save(model.state_dict(), self.save_path)\n",
        "            print ('model saved in ', self.save_path)\n",
        "            \n",
        "        self.best_prev_score = metric_value\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjzfcdKeEqjw"
      },
      "source": [
        "!ls /content/rnn_baseline/checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w7EZmS7DjG5"
      },
      "source": [
        "!mkdir -p /content/rnn_baseline/checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDG_4qafDmUA"
      },
      "source": [
        "#! rm -r /content/rnn_baseline/checkpoints\n",
        "#! mkdir -p /content/rnn_baseline/checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKvj5W8GBAym"
      },
      "source": [
        "path_to_checkpoints = '/content/rnn_baseline/checkpoints/'\n",
        "es = EarlyStopping(patience=3, mode='max', verbose=True, save_path=os.path.join(path_to_checkpoints, 'best_checkpoint.pt'), \n",
        "                   metric_name='ROC-AUC', save_format='torch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHNh4rd6A7eq"
      },
      "source": [
        "optimizer = torch.optim.Adam(lr=1e-3, params=model.parameters())\n",
        "num_epochs = 15\n",
        "train_batch_size = 128\n",
        "val_batch_szie = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "P1cc6IyK954C",
        "outputId": "f5d6bd2e-1126-4c43-dd42-ca311142e92e"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "    train_epoch(model, optimizer, dataset, weighted_sampler, batch_size=128, print_loss_every_n_batches=500)\n",
        "    \n",
        "    val_roc_auc = eval_model(model, dataset_val, weighted_sampler_val)\n",
        "    es(val_roc_auc, model)\n",
        "    \n",
        "    if es.early_stop:\n",
        "        print('Early stopping reached. Stop training...')\n",
        "        break\n",
        "    torch.save(model.state_dict(), os.path.join(path_to_checkpoints, f'epoch_{epoch+1}_val_{val_roc_auc:.3f}.pt'))\n",
        "    \n",
        "    train_roc_auc = eval_model(model, dataset, weighted_sampler)\n",
        "    print(f'Epoch {epoch+1} completed. Train roc-auc: {train_roc_auc}, Val roc-auc: {val_roc_auc}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-c2ea33f6cf32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Starting epoch {epoch+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_loss_every_n_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_roc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_sampler_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-e7bb85de2d7b>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, dataset_train, weighted_sampler, batch_size, print_loss_every_n_batches)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-eccbf6880ff7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cont_data, cat_data, seq_lengths)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_embs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m           x = [emb_layer(cat_data[:,:,i])\n\u001b[0;32m---> 54\u001b[0;31m             for i,emb_layer in enumerate(self.emb_layers)]\n\u001b[0m\u001b[1;32m     55\u001b[0m           \u001b[0;31m#print(cont_data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;31m#print(\"Shape \", len(x), x[1].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-eccbf6880ff7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_embs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m           x = [emb_layer(cat_data[:,:,i])\n\u001b[0;32m---> 54\u001b[0;31m             for i,emb_layer in enumerate(self.emb_layers)]\n\u001b[0m\u001b[1;32m     55\u001b[0m           \u001b[0;31m#print(cont_data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;31m#print(\"Shape \", len(x), x[1].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GLMkBh0IhBm"
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAtaMLfMAyfE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "3QLp2YWnIlRn",
        "outputId": "2650dde4-f8a6-4df8-d9a6-dd61848abc4d"
      },
      "source": [
        "no_of_epochs = 5\n",
        "#criterion = nn.MSELoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "epoch_loss = 0\n",
        "epoch_acc = 0\n",
        "batch_size = 128\n",
        "\n",
        "for epoch in range(no_of_epochs):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  n = 0\n",
        "  for y, cat_x, cont_x, seq_length in dataloader:\n",
        "    cat_x = cat_x.to(device)\n",
        "    cont_x = cont_x.to(device)\n",
        "    y  = y.to(device)\n",
        "    seq_length = seq_length.to(device)\n",
        "    #print(cat_x)\n",
        "    #print(cont_x)\n",
        "    #print(y)\n",
        "    #print(seq_length)\n",
        "\n",
        "    # Forward Pass\n",
        "    preds = model(cont_x, cat_x, seq_length).squeeze()\n",
        "    #print(\"Preds \", preds[0].shape)\n",
        "    \n",
        "    #print(y)\n",
        "    loss = criterion(preds, y)\n",
        "    #print(\"Preds \", preds)\n",
        "    #compute the binary accuracy\n",
        "    #acc = binary_accuracy(preds, y)\n",
        "    acc = roc_auc_score_s(preds, y)   \n",
        "    \n",
        "    # Backward Pass and Optimization\n",
        "    optimizer.zero_grad()\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #loss and accuracy\n",
        "    epoch_loss += loss.item()  \n",
        "    epoch_acc += acc.item()  \n",
        "    n += 1\n",
        "  print(\"n\", n)\n",
        "  print(f'\\tTrain Loss: {epoch_loss / n:.3f} | Train Acc: {epoch_acc / n:.2f}%')\n",
        "  #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "  val_roc_auc = eval_model(model, dataset_val, weighted_sampler_val)\n",
        "  print(f'Epoch {epoch+1} completed. Val roc-auc: {val_roc_auc}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-29f0563f5232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m#print(\"Preds \", preds[0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-eccbf6880ff7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cont_data, cat_data, seq_lengths)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_embs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m           x = [emb_layer(cat_data[:,:,i])\n\u001b[0;32m---> 54\u001b[0;31m             for i,emb_layer in enumerate(self.emb_layers)]\n\u001b[0m\u001b[1;32m     55\u001b[0m           \u001b[0;31m#print(cont_data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;31m#print(\"Shape \", len(x), x[1].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-eccbf6880ff7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_embs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m           x = [emb_layer(cat_data[:,:,i])\n\u001b[0;32m---> 54\u001b[0;31m             for i,emb_layer in enumerate(self.emb_layers)]\n\u001b[0m\u001b[1;32m     55\u001b[0m           \u001b[0;31m#print(cont_data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;31m#print(\"Shape \", len(x), x[1].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTr8IdCrgfUx"
      },
      "source": [
        "###Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f74jQUBsI1CK"
      },
      "source": [
        "! ls $path_to_checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX41LRDsPGOz",
        "outputId": "db0447e7-0734-4569-9552-48f6cabdbdc7"
      },
      "source": [
        "model.load_state_dict(torch.load(os.path.join(path_to_checkpoints, 'best_checkpoint.pt')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "foXXLVeDPJ8t",
        "outputId": "20156a96-b44f-478d-e8e8-befbdfb6c014"
      },
      "source": [
        "test_preds = inference(model, dataset_test, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-f2693d35fe33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-ce723259c338>\u001b[0m in \u001b[0;36minference\u001b[0;34m(model, dataset_test, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPadSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mapp_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mcat_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcont_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcont_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-54036ceff17f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0;31m#print(self.ids[idx])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m       \u001b[0;31m#print(self.cont_X[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0mout_cont\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcont_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#, dtype=np.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 21099 is out of bounds for axis 0 with size 21099"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ_c9xBXPcxO"
      },
      "source": [
        "test_preds.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t89IkWSpPdST"
      },
      "source": [
        "test_preds.to_csv('rnn_baseline_submission.csv', index=None) # ~ 0.750 на public test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR0Q_TY5Pf9D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-1Zqx7PVNmf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}